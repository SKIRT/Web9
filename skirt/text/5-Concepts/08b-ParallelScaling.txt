/**

\page ParallelScaling Scaling of parallel programs

\section ParallelScalingIntro Introduction

No matter how big the effort, a computer program can never be made entirely parallel. If a program could be perfectly
parallelized, the runtime of the program would keep decreasing with the same rate at which the number of parallel
processes increases. There are however a few factors that prevent this perfect behaviour. First of all, not all
operations in a serial program can be broken down into smaller operations that can then be executed by different
processors. As an example, input and output can be included in these kinds of operations. As a result, some portion of
the program is always serial, and will thus require a certain runtime \f$T_s\f$ irrespective of the number of
processes. This principle is illustrated in the figure below.

\image html parallel_serialparallel1.png

Secondly, an important aspect of parallel computing is communication. Although some applications require a very limited
amount of communication between processors, some form of communication in a parallel program is inevitable. The
bottleneck for the speed of the communication is the throughput or bandwidth of the communication network. In contrast
to the time \f$T_s\f$ spent on the execution of the serial portion of the program, the time required for communication
generally increases with the number of processes used. There are also other overheads of parallelization, such as
<em>idle time</em>. This is the time processes or threads do no work while they wait for further instructions. The
effect of overhead on the runtime of a parallel program is illustrated below.

\image html parallel_serialparallel2.png

\section ParallelScalingScaling Scaling

The behaviour of the total runtime of a program corresponding to an increase in the amount of parallel processors this
program is run on, is called \em scaling. The quantity that is mostly used to study scaling is called the \em speedup.
The speedup \f$S\f$ refers to how much faster a program runs when it is run in parallel, compared to when it is run as
a serial or sequential algorithm. If \f$T_1\f$ is the time needed for a serial run (on one processor) and \f$T_n\f$ is
the runtime of the parallel algorithm with \f$n\f$ processors, the speedup for \f$n\f$ processors can be defined as:

\f[ S_n = \frac{T_1}{T_n} \f]

Theoretically, if a program would be perfectly parallelized, the runtime would decrease as \f$T_n = \tfrac{T_1}{n}\f$
with \f$n\f$ the number of parallel processors. In this case, the scaling is said to be linear. The <em>linear
speedup</em> or <em>ideal speedup</em> is thus given by \f$S_n = n\f$. In practice, a program can never show linear
scaling, due to the reasons described above. In a simplified case where the communication bottleneck is ignored, we can
derive a simple equation describing the speedup as a function of the number of parallel processes. If \f$T_s\f$ is the
time spent on serial parts of the program, and \f$T_p\f$ is the amount of time spent (by a serial processor) on parts
of the program that can be done in parallel, \f$T_1\f$ and \f$T_n\f$ can be written as:

\f[ T_1 = T_s + T_p \f]
\f[ T_n = T_s + \tfrac{T_p}{n} \f]

The speedup becomes:

\f[ S_n = \frac{T_s + T_p}{T_s + \tfrac{T_p}{n}} \f]

We can now introduce the following quantities:

\f[ s \equiv \frac{T_s}{T_1} \f]
\f[ p \equiv \frac{T_p}{T_1} \f]

These quantities represent respectively the portion of the time spent on serial parts and the portion of the time spent
on parallelized parts. The equation for the speedup can now be rewritten as:

\f[ S_n = \frac{1}{1-p+\tfrac{p}{n}} \f]

Here, we have made use of the fact that \f$s = 1 - p\f$. The above equation is known as <em>Amdahl’s law</em>, named
after computer architect Gene Amdahl. A plot of this relation for different values of the parameter \f$p\f$ is shown in
the following figure.

\image html parallel_amdahl.png

As can be seen from the curve, or from Amdahl's law by letting \f$n \rightarrow \infty \f$, the speedup reaches a
maximum value given by:

\f[ S_{\infty}= \frac{1}{1-p} \f]

This value, corresponding to a certain value of \f$p\f$, is called the <em>theoretical maximum speedup</em>. Thus, the
total runtime of the program will in the best case be equal to \f$T_s\f$, the runtime of the serial portion of the
program. In this case, the parallel portion of the program is executed infinitely fast. As seen in the figure, the
speedup gradually flattens out to its asymptotic value. This means that at some point, adding more processors into the
computation gives no true benefit. In a practical application, it is therefore important to empirically determine the
speedup curve. If this curve shows that adding more than a certain amount of processors does not increase the speedup
appreciably, adding those processors should be avoided. After all, most of the time on each individual
processor will be used by executing the serial part (in a multi-processing situation) or this time will be wasted by
remaining idle (in a multi-threading situation). In any realistic case, adding processors will eventually also provide
a significant negative contribution to the speedup for large \f$n\f$, due to the communication overhead.

Despite its simplicity, Amdahl’s law provides a useful tool of quantifying the maximum number of processors that can be
allowed to participate in the parallel execution of a program. Let’s say a program is run repeatedly with a
different number of parallel processes, and the speedup is measured for each run. If we assume that the number of
processors used for these runs is not too large, and consequently the communication time is still one or more
magnitudes smaller then the total execution time of the program, we can expect the speedups to follow Amdahl’s law.
Fitting the observed speedups to this equation results in a certain value of the parameter \f$p\f$, the parallel
portion of the program. With this value of \f$p\f$, Amdahl’s law allows us to extrapolate the observed speedups to
higher numbers of processors. The part of the curve where the speedups flatten out, allows us to determine an absolute
upper limit to the number of processors that should be used with the particular program.

Another use of Amdahl’s law can be illustrated in the following way. Let’s say we have a program that is currently
serial and we want to look into the advantage of parallelizing it. Assume that we know what parts of the program are
impossible or extremely difficult to parallelize and what parts could be parallelized. By analyzing the time spent in
these parts of the program, we could find for example that the strictly serial part takes 25% of the computation time
while the other part takes 75% of the time. Without the necessity of parallelizing anything, the equation above tells
us that under the best conditions the maximum speedup will be 4 regardless of the number of processors.

*/
