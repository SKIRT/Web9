/**

\page UserStatistics Reliability statistics for simulated fluxes

This page describes SKIRT's capabilities for obtaining reliability statistics (a form of "error bars") for the fluxes
generated by the instruments in the simulation.


\section UserStatisticsObjectives Background and objectives

A SKIRT simulation discretizes all relevant physical quantities along spatial and spectral dimensions and represents
the flow of radiative energy using a finite number of photon packets. These numerical approximations necessarily affect
the simulation results. A common method to get a handle on these inaccuracies is to perform a series of convergence
tests, verifying that the results are stable for increasing discretization resolution.

Moreover, the Monte Carlo radiative transfer method employed by SKIRT inherently introduces noise in the simulation
results. The various acceleration and variance reduction techniques make it impossible to precisely predict these noise
levels across the spatial and/or spectral dimension. While convergence tests remain an important tool to verify overall
robustness, sometimes one requires a more quantitative analysis of the noise levels for a given simulation result, such
as the individual pixels in an image. This can be achieved using the optional statistics output by the SKIRT
instruments.

The treatment below is based on the discussion in the Overview and Theory manual for MCNP, a Monte Carlo
N-Particle transport code developed by Los Alamos National Laboratory in the United States. For  more information,
see [Camps and Baes 2018](https://ui.adsabs.harvard.edu/abs/2018ApJ...861...80C/abstract),
[Camps and Baes 2020](https://ui.adsabs.harvard.edu/abs/2020A%26C....3100381C/abstract), and references therein.


\section UserStatisticsMetrics Statistical metrics

A SKIRT instrument defines a set of bins that each record flux contributions in a specific spatial and spectral
interval. The total simulation result for a given bin is obtained by accumulating the contributions \f$w_i\f$ of
individual photon packets, i.e. \f$\sum_i w_i\f$, where the index \f$i\f$ and the sum run over the \f$N\f$ photon
packets launched during the simulation. All contributions to the same bin from the complete emission and scattering
history of a given photon packet are aggregated into a single contribution \f$w_i\f$. If statistics are requested, the
instrument tracks the sums \f$W_k=\sum_i w_i^k\f$ for \f$k=0,1,2,3,4\f$ during the simulation (as opposed to just the
sum for \f$k=1\f$) and outputs these data alongside the regular results. The sum \f$W_0\f$ yields the number of photon
packet contributions to the given bin, which by itself may be an interesting value. Using the higher order sums one can
obtain more important statistical metrics.

Foremost, the relative error, \f$R\f$, is given by

\f[
R = \left[ \frac{W_2}{W_1^2} - \frac{1}{N} \right]^{1/2}.
\f]

The relative error \f$R\f$ should be smaller than 0.1 for the corresponding result to be considered reliable. In that
case, \f$R\f$ can indeed be interpreted as a relative error on the result. In the range \f$0.1<R<0.2\f$, however,
results are questionable, and for \f$R>0.2\f$, results are unreliable.

The variance of the variance, VOV, is a higher-order statistic given by

\f[
\mathrm{VOV} = \frac{ W_4 - 4 W_1 W_3/N + 8 W_2 W_1^2/N^2 - 4 W_1^4/N^3 - W_2^2/N }
{\left[ W_2 - W_1^2/N \right]^2}.
\f]

The VOV measures the statistical uncertainty in the value for \f$R\f$. It is much more sensitive to large fluctuations
in the \f$w_i\f$ values than is \f$R\f$, and it can thus detect situations where the obtained \f$R\f$ value is
unreliable. The value of the VOV should be below 0.1 to ensure a reliable confidence interval.

Another useful quantity is the figure of merit, FOM, defined as

\f[
\mathrm{FOM} = \frac{1}{R^2\,T},
\f]

where \f$T\f$ is the computer time spent on the simulation in seconds. Because the computer time is roughly
proportional to the number of photon packets \f$N\f$ and the square of the relative error should scale more or less as
\f$1/N\f$ (for large \f$N\f$), the FOM should be approximately constant once the solution has converged. The evolution
of the FOM for increasing \f$N\f$ can thus be used as a reliability indicator. The FOM also provides a measure for the
efficiency or `merit' of a particular method for solving the problem at hand. A higher FOM indicates that the
simulation can reach a given noise level in less computer time.


\section UserStatisticsConfiguration Configuration

Tracking and outputting statistics can be enabled for any SKIRT instrument individually by setting its \em
recordStatistics property to true. As indicated above, the output includes the sums \f$W_k=\sum_i w_i^k\f$
(\f$k=0,1,2,3,4\f$) for each instrument bin, from which one can easily calculate the corresponding values for the
\f$R\f$ and VOV metrics. Keep in mind that gathering and storing this extra information uses both memory and processing
time.

To obtain the correct metrics, it is important to configure the instrument with the precise spatial and spectral
resolution of interest. Specifically, rebinning (combining the data for two or more adjacent bins) after the fact does
_not_ yield the correct metrics. This is so because multiple contributions caused by a given photon packet that happen
to arrive in a particular bin cannot be considered statistically independent and thus must be (and are) aggregated into
a single \f$w_i\f$ value. This can happen, for example, when a packet scatters multiple times in the line-of-sight of
the bin. This aggregation issue is irrelevant for a regular flux calculation, corresponding to the first order sum
\f$W_1\f$, because the contributions are added linearly. However, the aggregation does matter for the higher order
sums, which are nonlinear expressions of the individual contributions.


\section UserStatisticsExamples Examples

*/
