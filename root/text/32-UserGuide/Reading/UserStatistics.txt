/**

\page UserStatistics Reliability statistics for simulated fluxes

This page describes SKIRT's capabilities for obtaining reliability statistics (a form of "error bars") for the fluxes
generated by the instruments in the simulation.


\section UserStatisticsObjectives Background and objectives

A SKIRT simulation discretizes all relevant physical quantities along spatial and spectral dimensions and represents
the flow of radiative energy using a finite number of photon packets. These numerical approximations necessarily affect
the simulation results. A common method to get a handle on these inaccuracies is to perform a series of convergence
tests, verifying that the results are stable for increasing discretization resolution.

Moreover, the Monte Carlo radiative transfer method employed by SKIRT inherently introduces noise in the simulation
results. The various acceleration and variance reduction techniques make it impossible to precisely predict these noise
levels across the spatial and/or spectral dimension. While convergence tests remain an important tool to verify overall
robustness, sometimes one requires a more quantitative analysis of the noise levels for a given simulation result, such
as the individual pixels in an image. This can be achieved using the optional statistics output by the SKIRT
instruments.

The treatment below is based on the discussion in the Overview and Theory manual for MCNP, a Monte Carlo
N-Particle transport code developed by Los Alamos National Laboratory in the United States. For  more information,
see [Camps and Baes 2018](https://ui.adsabs.harvard.edu/abs/2018ApJ...861...80C/abstract),
[Camps and Baes 2020](https://ui.adsabs.harvard.edu/abs/2020A%26C....3100381C/abstract), and references therein.


\section UserStatisticsMetrics Statistical metrics

A SKIRT instrument defines a set of bins that each record flux contributions in a specific spatial and spectral
interval. The total simulation result for a given bin is obtained by accumulating the contributions \f$w_i\f$ of
individual photon packets, i.e. \f$\sum_i w_i\f$, where the index \f$i\f$ and the sum run over the \f$N\f$ photon
packets launched during the simulation. All contributions to the same bin from the complete emission and scattering
history of a given photon packet are aggregated into a single contribution \f$w_i\f$. If statistics are requested, the
instrument tracks the sums \f$W_k=\sum_i w_i^k\f$ for \f$k=0,1,2,3,4\f$ during the simulation (as opposed to just the
sum for \f$k=1\f$) and outputs these data alongside the regular results. The sum \f$W_0\f$ yields the number of photon
packet contributions to the given bin, which by itself may be an interesting value. Using the higher order sums one can
obtain more important statistical metrics.

Foremost, the relative error, \f$R\f$, is given by

\f[
R = \left[ \frac{W_2}{W_1^2} - \frac{1}{N} \right]^{1/2}.
\f]

The relative error \f$R\f$ should be smaller than 0.1 for the corresponding result to be considered reliable. In that
case, \f$R\f$ can indeed be interpreted as a relative error on the result. In the range \f$0.1<R<0.2\f$, however,
results are questionable, and for \f$R>0.2\f$, results are unreliable.

The variance of the variance, VOV, is a higher-order statistic given by

\f[
\mathrm{VOV} = \frac{ W_4 - 4 W_1 W_3/N + 8 W_2 W_1^2/N^2 - 4 W_1^4/N^3 - W_2^2/N }
{\left[ W_2 - W_1^2/N \right]^2}.
\f]

The VOV measures the statistical uncertainty in the value for \f$R\f$. It is much more sensitive to large fluctuations
in the \f$w_i\f$ values than is \f$R\f$, and it can thus detect situations where the obtained \f$R\f$ value is
unreliable. The value of the VOV should be below 0.1 to ensure a reliable confidence interval.

Another useful quantity is the figure of merit, FOM, defined as

\f[
\mathrm{FOM} = \frac{1}{R^2\,T},
\f]

where \f$T\f$ is the computer time spent on the simulation in seconds. Because the computer time is roughly
proportional to the number of photon packets \f$N\f$ and the square of the relative error should scale more or less as
\f$1/N\f$ (for large \f$N\f$), the FOM should be approximately constant once the solution has converged. The evolution
of the FOM for increasing \f$N\f$ can thus be used as a reliability indicator. The FOM also provides a measure for the
efficiency or `merit' of a particular method for solving the problem at hand. A higher FOM indicates that the
simulation can reach a given noise level in less computer time.


\section UserStatisticsConfiguration Configuration

Tracking and outputting statistics can be enabled for any SKIRT instrument individually by setting its \em
recordStatistics property to true. As indicated above, the output includes the sums \f$W_k=\sum_i w_i^k\f$
(\f$k=0,1,2,3,4\f$) for each instrument bin, from which one can easily calculate the corresponding values for the
\f$R\f$ and VOV metrics. Keep in mind that gathering and storing this extra information uses both memory and processing
time.

To obtain the correct metrics, it is important to configure the instrument with the precise spatial and spectral
resolution of interest. Specifically, rebinning (combining the data for two or more adjacent bins) after the fact does
_not_ yield the correct metrics. This is so because multiple contributions caused by a given photon packet that happen
to arrive in a particular bin cannot be considered statistically independent and thus must be (and are) aggregated into
a single \f$w_i\f$ value. This can happen, for example, when a packet scatters multiple times in the line-of-sight of
the bin. This aggregation issue is irrelevant for a regular flux calculation, corresponding to the first order sum
\f$W_1\f$, because the contributions are added linearly. However, the aggregation does matter for the higher order
sums, which are nonlinear expressions of the individual contributions.


\section UserStatisticsExample1 Example: radiation penetrating thick slab

A very informative, albeit somewhat theoretical, application of SKIRT's statistical metrics is provided by [Camps and
Baes 2020](https://ui.adsabs.harvard.edu/abs/2020A%26C....3100381C/abstract). The SKIRT simulation in this example
includes a cuboidal slab of material illuminated by a monochromatic point source. The distant (parallel-projected)
instrument on the opposite side covers a slice across the length of the slab and is offset from the center so that the
point source is not in the field of view. Each pixel in the instrument frame spans the full width of the slice, causing
all photon packet contributions along the width of the slice to end up in the same pixel, and the set of pixels to form
a linear sequence of thin rectangles along the length of the slice. The figure below shows the flux density profile
detected by this instrument for a varying total number of photon packets \f$N_\mathrm{pp}\f$ launched during the
simulation (top row) and the corresponding values of the relative error \f$R\f$ (middle row) and the variance of the
variance VOV (bottom row).

|                               |                                |
|-------------------------------|--------------------------------|
| ![ ](UserStatisticsSlab5.png) | ![ ](UserStatisticsSlab75.png) |

The left panel illustrates that for an optical depth across the slab of \f$\tau=5\f$ the results are essentially
converged starting at \f$N_\mathrm{pp}\geq10^7\f$. In this case, \f$R<0.1\f$ and the value of the VOV is below
\f$10^{-2}\f$ (which is why the corresponding curves are missing), so that both \f$R\f$ and the actual simulation
results can be deemed reliable. The situation shown in the right panel for an optical depth of \f$\tau=75\f$ is totally
different. The average flux density rises significantly with an increasing number of photon packets, which is a strong
indication that something fishy is going on. The good news is that we can now use statistical analysis to evaluate the
results. It appears that \f$R\f$ (finally) dips under the reliability threshold for \f$N_\mathrm{pp}=10^{12}\f$.
However, the VOV is still well above the threshold, so the value of \f$R\f$ cannot really be trusted. This is reflected
by two features apparent in the flux density profiles. Firstly, extrapolation of the progression of the flux profile
average with increasing \f$N_\mathrm{pp}\f$ seems to indicate room for a further increase. Secondly, the flux density
curve shows several large peaks of an order of magnitude or more even for the simulation with
\f$N_\mathrm{pp}=10^{12}\f$. We can conclude from this analysis that the results are still not fully converged.

The simulation with \f$N_\mathrm{pp}=10^{12}\f$ shown in the right panel ran for over 6 hours on a 24-core server.
Calculating the next step in the progression, i.e. \f$N_\mathrm{pp}=10^{14}\f$, would take 25 days on the same machine.
While using a larger, multi-node computer system could shorten the elapsed time, there is no guarantee of convergence.
In fact, the lack of progression of the VOV values up to \f$N_\mathrm{pp}=10^{12}\f$ seems to indicate that one would
need to process several orders of magnitude more photon packets for the results to be converged with an acceptable
signal to noise ratio.


\section UserStatisticsExample2 Example: high-resolution synthetic galaxy images

A more practical application of SKIRT's statistical metrics is provided by [Camps et al.
2022](https://ui.adsabs.harvard.edu/abs/2022MNRAS.512.2728C/abstract). These authors produce high-resolution synthetic
UVâ€“submm images for Milky Way-mass simulated galaxies from the ARTEMIS project. To evaluate convergence on a pixel by
pixel basis, they calculate the relative error \f$R\f$ for each pixel in a representative set of broadband images at
selected viewing angles. The figure below shows these statistics for the face-on view of a representative ARTEMIS
galaxy in four selected bands from UV to submm wavelengths.

|                                      |
|--------------------------------------|
| ![ ](UserStatisticsGalaxyFrames.png) |

The synthetic surface brightness maps in the top row use a logarithmic colour scale; the transition between red and
blue marks 1/100 of the maximum surface brightness. Each of the underlying data frames has \f$1728^2\f$
\f$50\times50\f$ pc pixels, corresponding to the 86 kpc field of view. The second row (\f$b=1\f$) shows the
corresponding \f$R\f$ value for each of these pixels indicating reliable (\f$R<0.1\f$, green), questionable (\f$0.1 < R
< 0.2\f$, orange) and unreliable (\f$R > 0.2\f$, red) image areas. The third row (\f$b=2\f$) shows the same statistic
after \f$2\times2\f$ binning into \f$100\times100\f$ pc pixels. As expected, this binning results in a substantial
increase in reliability at the cost of lower resolution.

At the binned \f$b=2\f$ level, the reliable area (green) essentially covers all pixels with a value down to 1/100 of
the maximum surface brightness (yellow and red). At the original \f$b=1\f$ level, one needs to include the questionable
area (orange) to achieve a similar coverage. Generally, the FUV/NUV bands tend to show somewhat poorer statistics
because of the relatively lower fluxes and higher extinction involved in that wavelength range.


*/
